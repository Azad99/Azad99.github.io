<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Talal Ahmad | Robotics & AI Engineer</title>		
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="#" class="image avatar"><img src="images/talal2.jpg" alt="" /></a>
					<h1><strong>Talal Ahmad</strong><br />
					<span>Robotics & AI Engineer</span><br />
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
					<section id="one">
						<header class="major">
						<h2>About Me</h2>
						</header>
						<p>
						As a robotics engineer with a focus on mapping and localization, I develop intelligent systems that enable autonomous robots to understand and interact with their environment safely and efficiently.
						</p>
						<p>
						With a strong background in robotics, electronics, and mechanical systems—alongside experience in software development and program management—I take a systems-level approach to solving real-world challenges in autonomous navigation, perception, and control.
						</p>
						<p>
						My work bridges the gap between research and application, aligning with company’s mission to turn cutting-edge ideas into practical, industrial-strength robotics solutions. I thrive in interdisciplinary teams, enjoy tackling complex problems, and have a proven ability to lead and contribute to high-impact robotics projects from concept to deployment.
						</p>
						<p>
						I'm excited by the opportunity to help shape the future of autonomous robotics and contribute to innovations that have real societal value. If you'd like to collaborate or discuss opportunities, please feel free to contact me using the information below.
						</p>
					</section>
						<ul class="actions">
							<a href="#two" class="button">Learn More</a>
						</ul>
					</section>

				<!-- Two -->
					<section id="two">
						<h2>Projects</h2>
						<div class="row">
							<article class="col-6 col-12-xsmall work-item">
							<div class="image fit thumb" onclick="openModal('kukaModal')">
								<img src="images/fulls/task_1.gif" alt="KUKA youBot Project" />
								<h3>KUKA youBot Manipulation</h3>
							</div>
							</article>

							<div id="kukaModal" class="custom-modal">
							<div class="custom-modal-content">
								<span class="custom-modal-close" onclick="closeModal('kukaModal')">&times;</span>
								<h3>KUKA youBot Manipulation</h3>
								<p>The goal of this project is to drive the KUKA youBot to pick up a block at the start location and carry it to the desired location in the V-REP simulation software. The project covers the following topics:</p>
								<ul>
								<li>Planning the reference trajectory of the end-effector from start point to end point</li>
								<li>Generating the kinematics model of the youBot, including the mobile base with 4 mecanum wheels and the 5-joint robot arm</li>
								<li>Applying a feedforward + PI controller to drive the robot toward the reference trajectory</li>
								<li>Conducting the complete simulation in V-REP</li>
								</ul>

								<h2>Project Overview</h2>
								<h3>1. Kinematics Simulator for YouBot</h3>
								<p>I developed a program that calculates the robot’s next configuration based on the current configuration, joint velocities, and wheel velocities. Each line of the input CSV file contains 13 comma-separated values.</p>

								<div class="eq" style="font-family: Georgia, serif; font-size: 18px;">
								<strong>q =</strong>
								<span>
									[ &phi;<sub>chassis</sub>, x<sub>chassis</sub>, y<sub>chassis</sub>, J<sub>1</sub>, J<sub>2</sub>, J<sub>3</sub>, J<sub>4</sub>, J<sub>5</sub>, W<sub>1</sub>, W<sub>2</sub>, W<sub>3</sub>, W<sub>4</sub>, Gripper ]
								</span>
								</div>

								<p>This corresponds to:</p>
								<ul>
								<li>φ<sub>chassis</sub>: Chassis orientation (yaw)</li>
								<li>x<sub>chassis</sub>: Chassis X-position</li>
								<li>y<sub>chassis</sub>: Chassis Y-position</li>
								<li>J<sub>1</sub> to J<sub>5</sub>: Arm joint angles</li>
								<li>W<sub>1</sub> to W<sub>4</sub>: Wheel angles</li>
								<li>Gripper state: 0 (open) or 1 (closed)</li>
								</ul>
								<p>Velocity limits are enforced to prevent unsafe or unrealistic movements.</p>

								<h3>2. End-Effector Trajectory Planning</h3>
								<p>I created a trajectory generator for the end-effector by specifying its poses at various keyframes relative to either the world or cube frame. The planned trajectory includes the following steps:</p>
								<ol>
								<li>Start at rest in the initial configuration</li>
								<li>Move to standoff position (above cube)</li>
								<li>Descend to grasp position</li>
								<li>Close the gripper</li>
								<li>Return to standoff with the object</li>
								<li>Move to goal standoff position</li>
								<li>Move to final goal position</li>
								<li>Open the gripper</li>
								<li>Return to standoff</li>
								</ol>
								<img src="images/fulls/task_1.gif" alt="Simulation" />

								<h3>3. Feedback Control for Trajectory Tracking</h3>
								<p>To ensure accurate tracking, I implemented a PI feedback controller in task space. The commanded end-effector twist ν(t) is computed using:</p>
								<p>
								ν(t) = [Ad<sub>X<sup>−1</sup>Xd</sub>] · ν<sub>d</sub>(t) + K<sub>p</sub> · X<sub>err</sub>(t) + K<sub>i</sub> · ∫<sub>0</sub><sup>t</sup> X<sub>err</sub>(τ) dτ
								</p>
								<ul>
								<li>ν(t): Actual commanded twist</li>
								<li>ν<sub>d</sub>(t): Desired twist</li>
								<li>X<sub>err</sub>(t): Error between current and desired configurations</li>
								<li>K<sub>p</sub>: Proportional gain</li>
								<li>K<sub>i</sub>: Integral gain</li>
								</ul>

								<p>Controller performance insights:</p>
								<ul>
								<li>High K<sub>p</sub>, low K<sub>i</sub>: Smooth, fast convergence with minor overshoot</li>
								<li>Low K<sub>p</sub>, high K<sub>i</sub>: Noticeable overshoot, slower convergence</li>
								</ul>

								<h2>Results:</h2>
								<h3>1. Motion Planning with Varying Cube Positions</h3>
								<p>Simulations were run using various initial and final cube positions with different robot configurations. The robot consistently followed the planned path and completed the object manipulation task.</p>

								<h3>2. Analysis of Control Gains</h3>
								<p>The effect of different control gains on tracking accuracy was evaluated:</p>
								<ul>
								<li>Resulted in overshoot and slower convergence</li>
								</ul>
								<img src="images/fulls/kuka_re1.png" alt="KUKA Arm" />
								<ul>
								<li>Produced smooth, stable motion with minimal error</li>
								</ul>
								<img src="images/fulls/kuka_re2.png" alt="KUKA Arm" />

								<p>These results highlight the importance of tuning control gains for optimal performance in mobile manipulation tasks.</p>
								<p><strong>Note:</strong> Due to client confidentiality, the source code is not publicly available.</p>							
							</div>
						</div>

						<!-- Three -->
							</article>
							<article class="col-6 col-12-xsmall work-item">
								<div class="image fit thumb" onclick="openModal('PoseCNNModal')">
							<img src="images/fulls/Demo.gif" alt="KUKA youBot Project" />
							<h3>PoseCNN Implementation with ROS</h3>
							</article>
							<div id="PoseCNNModal" class="custom-modal">
							<div class="custom-modal-content">
								<span class="custom-modal-close" onclick="closeModal('PoseCNNModal')">&times;</span>
								<h3>PoseCNN Implementation with ROS</h3>
								<p>PoseCNN is a convolutional neural network architecture designed to estimate the 6D pose (3D translation + 3D rotation) of objects directly from RGB images. It operates in two main stages: semantic segmentation to localize objects, and pose regression to estimate their 3D position and orientation. The model leverages a modified VGG16 backbone and integrates translation regression and quaternion-based rotation estimation in a unified framework.</p>
								<p>For custom objects, PoseCNN requires:</p>
								<ul>
								<li>A synthetic or real dataset of labeled 6D poses with accurate object CAD models or meshes.</li>
								<li>Training of the network on these new objects using either the provided training pipelines or fine-tuning pre-trained weights.</li>
								<li>Optional integration with DenseFusion or ICP refinement for increased pose accuracy using RGB-D data.</li>
								</ul>
								<p>The architecture is particularly suited for robotics applications such as bin picking, AR interaction, or autonomous manipulation, where real-time object pose understanding is critical. By learning pose information end-to-end from RGB images, PoseCNN avoids heavy reliance on depth data or keypoint detection, making it flexible for various environments and object types.</p>
								<img src="images/fulls/Demo.gif" alt="Simulation" />
								<p><strong>Note:</strong> Due to client confidentiality, the source code is not publicly available.</p>							
							</div>
						</div>


						<!-- Three -->
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<div class="image fit thumb" onclick="openModal('vio')">
						<img src="images/fulls/vio.gif" alt="VIO" />
						<h3>Real-Time Trajectory Generation using Visual SLAM</h3>
						</article>
						<div id="vio" class="custom-modal">
						<div class="custom-modal-content">
							<span class="custom-modal-close" onclick="closeModal('vio')">&times;</span>
							<h3>Real-Time Trajectory Generation using Visual SLAM</h3>
							<p>This project demonstrates a complete workflow for integrating real-time visual tracking data with industrial robot motion planning. Using external camera tracking and pose estimation, I developed a system that processes raw spatial data, smooths it for accuracy, and generates executable movement paths for a UR robot. The goal was to enable precise and adaptive robot control based on environmental feedback, supporting applications such as smart manipulation, inspection, or dynamic interaction in collaborative settings.</p>
							<ul>
								<li><span class="feature-title">Live Sensor Fusion Demo:</span> The program streams video from an AI camera and, at the same time, reads the current position of a collaborative robot arm. Every frame is matched with the robot’s pose so you always know exactly where the camera and robot are in space.</li>
						  
								<li><span class="feature-title">Instant 3-D Visualisation:</span> As the system runs, an interactive 3-D window shows the camera’s trajectory and orientation as a little wire-frame camera icon moving through space. You can watch the path unfold in real time while the robot works.</li>
						  
								<li><span class="feature-title">One-Key Data Capture:</span> Pressing a single key tells the program to start recording. From that moment on, every new camera view and robot pose is logged automatically so you can replay or analyse the session later without disrupting the demo.</li>
						  
								<li><span class="feature-title">Automatic Session Log:</span> The app quietly writes everything to a lightweight JSON file: the very first camera view (for reference), every subsequent view, and each matching robot pose. This builds a ready-to-use dataset for calibration, research or quality control.</li>
						  
								<li><span class="feature-title">Smooth User Experience:</span> A background thread keeps all the heavy lifting out of the way, ensuring the 3-D viewer never stutters and the camera preview remains fluid. If you’re done, just close the window or tap “q” and the program shuts down gracefully.</li>
							  </ul>

							<!-- ✅ Proper video tag -->
							<video width="100%" controls autoplay muted loop>
								<source src="images/fulls/Untitled video - Made with Clipchamp.mp4" type="video/mp4">
								Your browser does not support the video tag.
							</video>
							<h1>Robot Path Generation & Execution</h1>
							<ul>
							  <li><span class="feature-title">Turns Raw Tracking Data into a Smooth Robot Path:</span> The program reads a JSON file of camera-tracked points, gently filters out noise, and converts the trail into evenly spaced waypoints the robot can follow.</li>
						  
							  <li><span class="feature-title">Creates an Instant 3-D Preview:</span> Before the robot ever moves, the trajectory is plotted in a colourful 3-D window so you can visually confirm that every point sits where you expect.</li>
						  
							  <li><span class="feature-title">Automatically Generates a Full Motion Plan:</span> From a single “home” pose, the script assembles a complete move-sequence: first a safe joint move to the start, then a continuous linear glide through each waypoint at a comfortable speed.</li>
						  
							  <li><span class="feature-title">Runs the Robot and Reports Progress Live:</span> Once you hit “go”, the robot executes the path autonomously while the console keeps you posted (“Moving to path waypoint …”) so you always know how far it’s gotten.</li>
						  
							  <li><span class="feature-title">Exports the Final Path for Reuse:</span> All corrected waypoints are saved to a new JSON file, giving you a ready-made blueprint for future runs, simulations, or documentation.</li>
							</ul>							
							<!-- ✅ Proper video tag -->
							<video width="100%" controls autoplay muted loop>
								<source src="images/fulls/Untitled video - Made with Clipchamp (2).mp4" type="video/mp4">
								Your browser does not support the video tag.
							</video>
							<p><strong>Note:</strong> Due to client confidentiality, the source code is not publicly available.</p>							
						</div>
					</div>
						



					<!-- Four -->
					<article class="col-6 col-12-xsmall work-item">
						<div class="image fit thumb" onclick="openModal('handeye')">
						<img src="images/fulls/hand eye.gif" alt="Hand-Eye Calibration" />
						<h3>Hand-Eye Calibration using OpenCV and PyQt5</h3>
						</div>
					</article>
					
					<div id="handeye" class="custom-modal">
						<div class="custom-modal-content">
						<span class="custom-modal-close" onclick="closeModal('handeye')">&times;</span>
						<h3>Hand-Eye Calibration using OpenCV and PyQt5</h3>
					
						<p><strong>Purpose:</strong> A desktop application that simplifies the entire hand-eye calibration workflow for camera-guided robots. It lets you capture synchronized robot poses and camera images, then runs Charuco-board calibration and five classic hand-eye algorithms—all in one click.</p>
					
						<h3>Key Capabilities</h3>
						<table class="features-table">
							<thead>
							<tr>
								<th>Feature</th>
								<th>How it helps</th>
							</tr>
							</thead>
							<tbody>
							<tr>
								<td>Live robot &amp; camera link</td>
								<td>Connects to Universal Robots, Elite, or Techman arms over RTDE/RTSI; streams live colour + depth frames from Orbbec, Realsense, or OAK-D.</td>
							</tr>
							<tr>
								<td>One-button data capture</td>
								<td>Records the robot’s joint/TCP pose and grabs a perfectly timestamped camera image into a numbered dataset folder.</td>
							</tr>
							<tr>
								<td>Batch Charuco detection</td>
								<td>Loads any folder of PNGs, auto-detects the Charuco board, and stores all corner IDs for calibration.</td>
							</tr>
							<tr>
								<td>Five hand-eye methods</td>
								<td>Computes PARK, ANDREFF, DANIILIDIS, HORAUD, and TSAI solutions in sequence, logs each rotation/translation pair, and saves them to a text file.</td>
							</tr>
							<tr>
								<td>Rich GUI with live feed</td>
								<td>PyQt5 interface shows connection status, camera preview, and a scrollable timestamped log; multithreaded so the UI never blocks.</td>
							</tr>
							<tr>
								<td>Portable results</td>
								<td>Outputs JSON/CSV pose data and annotated “detected_*.png” images for verifiable, reproducible calibration records.</td>
							</tr>
							</tbody>
						</table>
					
						<h3>Why It Matters</h3>
						<p>This tool turns a traditionally command-line, script-heavy process into a turnkey workflow that technicians and researchers can run without coding. It speeds up data collection, reduces human error, and produces ready-to-use extrinsic parameters for vision-guided pick-and-place, inspection, or welding robots.</p>

						<video width="100%" controls autoplay muted loop>
							<source src="images/fulls/handeye.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					
							<p><strong>Note:</strong> Due to client confidentiality, the source code is not publicly available.</p>						
					</div>
				</div>
					

			

				<!-- Four -->
				<article class="col-6 col-12-xsmall work-item">
					<div class="image fit thumb" onclick="openModal('TurtleBot3')">
					<img src="images/fulls/turtle.gif" alt="Hand-Eye Calibration" />
					<h3>SLAM Benchmarking with TurtleBot3 (ROS + Gazebo)</h3>
					</div>
				</article>
					
				<div id="TurtleBot3" class="custom-modal">
					<div class="custom-modal-content">
					<span class="custom-modal-close" onclick="closeModal('TurtleBot3')">&times;</span>
						<h3>SLAM Benchmarking with TurtleBot3 (ROS + Gazebo)</h3>
						<p>This project explores and compares multiple <strong>Simultaneous Localization and Mapping (SLAM)</strong> algorithms using the TurtleBot3 robot in a Gazebo-based ROS simulation environment. The objective was to evaluate each method’s ability to build accurate maps and maintain localization under different conditions.
						</p>
					
						<!-- Objective -->
						<h3>Objective</h3>
						<p>
						Test and analyze various open-source SLAM algorithms in a controlled simulation, identifying each approach’s strengths and limitations for real-world robot navigation.
						</p>
					
						<!-- Technologies -->
						<h3>Technologies Used</h3>
						<ul>
						<li>Robot Operating System (ROS)  – <em>Melodic &amp; Noetic</em></li>
						<li>Gazebo Simulator</li>
						<li>TurtleBot3 Waffle Pi</li>
						<li>Rviz for Visualization</li>
						<li>SLAM Packages:
							<ul>
							<li>GMapping (2D SLAM)</li>
							<li>Cartographer (Google’s real-time SLAM)</li>
							<li>Hector SLAM</li>
							<li>Karto SLAM</li>
							<li>TinySLAM</li>
							</ul>
						</li>
						</ul>
					
						<!-- Approach -->
						<h3>Approach</h3>
						<ol>
						<li>Built a virtual office-like environment in Gazebo with TurtleBot3 as the mobile platform.</li>
						<li>Launched each SLAM algorithm independently via ROS launch files and custom <code>.yaml</code> configs.</li>
						<li>Used keyboard teleoperation (<code>teleop</code>) to explore while visualizing map quality in Rviz.</li>
						<li>Evaluated outputs for map accuracy, drift, responsiveness, and CPU load.</li>
						</ol>
					
						<!-- Insights Table -->
						<h3>Insights &amp; Observations</h3>
						<table class="features-table">
						<thead>
							<tr>
							<th>Algorithm</th>
							<th>Strengths</th>
							<th>Weaknesses</th>
							</tr>
						</thead>
						<tbody>
							<tr>
							<td>GMapping</td>
							<td>Lightweight, easy to set up</td>
							<td>Loses accuracy with fast motion</td>
							</tr>
							<tr>
							<td>Cartographer</td>
							<td>Extremely accurate, fast updates</td>
							<td>CPU intensive, config-heavy</td>
							</tr>
							<tr>
							<td>Hector SLAM</td>
							<td>No odometry needed, fast response</td>
							<td>Map sometimes distorted in corners</td>
							</tr>
							<tr>
							<td>Karto SLAM</td>
							<td>Good quality with moderate tuning</td>
							<td>Less active community</td>
							</tr>
							<tr>
							<td>TinySLAM</td>
							<td>Very simple, minimal resource usage</td>
							<td>Limited robustness in complex environments</td>
							</tr>
						</tbody>
						</table>


						<video width="100%" controls autoplay muted loop>
							<source src="images/fulls/turtlevideo.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					

					
						<!-- Why It Matters -->
						<h3>Why It Matters</h3>
						<p>
						SLAM is the backbone of autonomous navigation in mobile robotics. This benchmarking effort deepened understanding of different SLAM techniques and provides a practical guide for selecting the right algorithm based on hardware constraints and mission requirements.
						</p>
					</div>  
			</div>



				<!-- Five -->
				<article class="col-6 col-12-xsmall work-item">
					<div class="image fit thumb" onclick="openModal('smartpick&place')">
					<img src="images/fulls/pick_and_place.gif" alt="Hand-Eye Calibration" />
					<h3>Smart Pick-and-Place GUI (Python + PyQt + RealSense + UR Robots)</h3>
					</div>
				</article>
					
				<div id="smartpick&place" class="custom-modal">
					<div class="custom-modal-content">
					<span class="custom-modal-close" onclick="closeModal('smartpick&place')">&times;</span>
						<<h2>Smart Pick-and-Place GUI (Python + PyQt + RealSense + UR Robots)</h2>
						<p>
						  A desktop application that turns an Intel RealSense camera, a UR robot arm, and a state-of-the-art object-segmentation model into an interactive pick-and-place workstation. Everything runs from a single PyQt window with live video, mouse-click grasp planning, and one-button execution.
						</p>
					  
						<h3>Core Workflow</h3>
						<ul>
						  <li><strong>Live RGB-D Feed:</strong>
							<ul>
							  <li>Starts an Intel RealSense pipeline and streams colour-over-depth imagery at 30 FPS.</li>
							  <li>Aligns depth to colour on-the-fly for accurate 3-D read-outs.</li>
							</ul>
						  </li>
						  <li><strong>Interactive Grasp Selection:</strong>
							<ul>
							  <li>Click anywhere on the live image to read its exact 3-D coordinates (via RealSense intrinsics).</li>
							  <li>A single key spawns the SAM segmentation network, outlines the object, and computes PCA for its principal axes.</li>
							</ul>
						  </li>
						  <li><strong>Automatic Grasp Pose Generation:</strong>
							<ul>
							  <li>Uses a custom Vacuum-Gripper model + spiral search to find the best suction pose along the major axis.</li>
							  <li>Converts image-plane grasp into a robot-base pose through a calibrated chain: <code>Base → Gripper → Camera</code>.</li>
							</ul>
						  </li>
						  <li><strong>Robot Control & Safety:</strong>
							<ul>
							  <li>Connects to Universal Robots (RTDE) and toggles teach mode automatically.</li>
							  <li>Generates a three-stage linear path (approach → grasp → retreat) with smooth velocity/acceleration limits.</li>
							  <li>Home, Move, Pick, Segment, and Grasp-Pose buttons are all multi-threaded to keep the UI responsive.</li>
							</ul>
						  </li>
						  <li><strong>Modular Worker Threads:</strong>
							<ul>
							  <li>Heavy tasks (e.g., segmentation, PCA, robot motion) run in background <code>QThreads</code>.</li>
							  <li>Signals carry numpy arrays, masks, and status strings back to the main thread without blocking video.</li>
							</ul>
						  </li>
						</ul>

						<video width="100%" controls autoplay muted loop>
							<source src="images/fulls/pickandplace.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					

					  
						<h3>Highlights for Stakeholders</h3>
						<table style="width: 100%; border-collapse: collapse;">
						  <thead>
							<tr style="background-color: #f4f4f4;">
							  <th style="text-align: left; padding: 8px; border: 1px solid #ccc;">Feature</th>
							  <th style="text-align: left; padding: 8px; border: 1px solid #ccc;">Value</th>
							</tr>
						  </thead>
						  <tbody>
							<tr>
							  <td style="padding: 8px; border: 1px solid #ccc;">One-click grasping demo</td>
							  <td style="padding: 8px; border: 1px solid #ccc;">Showcases real-time vision → planning → actuation in under a second.</td>
							</tr>
							<tr>
							  <td style="padding: 8px; border: 1px solid #ccc;">Re-usable codebase</td>
							  <td style="padding: 8px; border: 1px solid #ccc;">Modular workers mean you can swap in new cameras or robots with minimal edits.</td>
							</tr>
							<tr>
							  <td style="padding: 8px; border: 1px solid #ccc;">End-to-end calibration</td>
							  <td style="padding: 8px; border: 1px solid #ccc;">Uses pre-computed hand-eye matrices to convert clicks to base-frame coordinates.</td>
							</tr>
							<tr>
							  <td style="padding: 8px; border: 1px solid #ccc;">Safety-first controls</td>
							  <td style="padding: 8px; border: 1px solid #ccc;">Automatically toggles teach mode and ensures safe start/end poses.</td>
							</tr>
							<tr>
							  <td style="padding: 8px; border: 1px solid #ccc;">Scalable vision stack</td>
							  <td style="padding: 8px; border: 1px solid #ccc;">Integrates SAM now, but can support any PyTorch/TensorFlow model.</td>
							</tr>
						  </tbody>
						</table>

					</div>  
				</div>
	
























			<!-- Five -->
			<section id="Five">
			
				
			

					<section id="skills" class="skills-section">
						<h2 class="section-title">MY SKILLS</h2>
						<div class="skills-container">
						  
						  <!-- Skill Block -->
						  <div class="skill-category">
							<img src="images/skills/robotics.jpg" alt="Robotics Icon">
							<h3>Robotics</h3>
							<ul>
								<li>Robot Operating System (ROS 1 &amp; 2)</li>
								<li>Gazebo Simulator</li>
								<li>MoveIt Motion Planning Framework</li>
								<li>Rviz Visualization Tool</li>
								<li>UR10 Robot</li>
								<li>Elite Robot Platform</li>
								<li>Techman Robot</li>
								<li>KUKA Industrial Robot</li>
								<li>ABB Robot Systems</li>
								<li>TurtleBot Mobile Robot</li>
								<li>Arduino Microcontroller</li>
								<li>Jetson Nano</li>
							  </ul>
						  </div>
					  
						  <div class="skill-category">
							<img src="images/skills/programming.jpg" alt="Programming Icon">
							<h3>Programming &amp; Tools</h3>
							<ul>
								<li>Python</li>
								<li>C / C++</li>
								<li>Bash</li>
								<li>MATLAB</li>
								<li>Git</li>
								<li>HTML &amp; CSS</li>
								<li>JavaScript</li>
								<li>Docker</li>
								<li>Jenkins</li>
								<li>CI/CD Pipelines</li>
								<li>VS Code</li>
								<li>Linux</li>
							  </ul>
						  </div>
					  
						  <div class="skill-category">
							<img src="images/skills/computer vision.jpg" alt="Computer vision icon">
							<h3>Computer Vision</h3>
							<ul>
								<li>Image Processing</li>
								<li>3D Object Detection</li>
								<li>Segmentation</li>
								<li>SLAM (Simultaneous Localization and Mapping)</li>
								<li>Pose Estimation</li>
								<li>OpenCV</li>
								<li>Open3D</li>
								<li>CUDA Programming</li>
								<li>CARLA Simulator</li>
							  </ul>
						  </div>
					  
						  <div class="skill-category">
							<img src="images/skills/machine learning.jpg" alt="Machine learning Icon">
							<h3>Machine Learning</h3>
							<ul>
								<li>Supervised / Unsupervised Learning</li>
								<li>Deep Learning</li>
								<li>Reinforcement Learning</li>
								<li>Model Deployment</li>
								<li>PyTorch</li>
								<li>TensorFlow</li>
								<li>Scikit-learn</li>
								<li>Keras</li>
								<li>XGBoost</li>
							  </ul>
						  </div>
					  
						  <div class="skill-category">
							<img src="images/skills/cloud-deployment.jpg" alt="cloud-deployment Icon">
							<h3>Cloud &amp; Deployment</h3>
							<ul>
								<li>Docker</li>
								<li>Docker Compose</li>
								<li>Kubernetes (basic)</li>
								<li>Jenkins</li>
								<li>GitHub Actions</li>
								<li>Model Serving</li>
								<li>TensorFlow Serving</li>
								<li>TorchServe</li>
								<li>ONNX Runtime</li>
								<li>AWS (Amazon Web Services)</li>
								<li>Google Cloud Platform (GCP)</li>
								<li>Microsoft Azure (basic)</li>
							  </ul>
						  </div>


						  <div class="skill-category">
							<img src="images/skills/Data-Vizualisation.jpg" alt="data Visualisation Icon">
							<h3>Data &amp; Visualization</h3>
							<ul>
								<li>Pandas</li>
								<li>NumPy</li>
								<li>Matplotlib</li>
								<li>Seaborn</li>
								<li>Jupyter Notebook</li>
								<li>Streamlit</li>
							  </ul>
						  </div>



					  
						</div>
					</section>
					  


					
					</section>

						<!-- Four -->
						<section id="contact">
						<h2>Get In Touch</h2>
						<p>
							I'm always open to exciting opportunities, collaboration ideas, or just a good conversation about robotics, AI, or innovative tech.
							Whether you have a project in mind, want to connect professionally, or simply say hello — feel free to reach out!
						</p>

						<div class="row">
							<!-- Contact Form -->
							<div class="col-8 col-12-small">
								<form id="contact-form" action="https://formspree.io/f/mzzgprnr" method="POST">
								<div class="row gtr-uniform gtr-50">
								<div class="col-6 col-12-xsmall">
									<input type="text" name="name" id="name" placeholder="Name" required />
								</div>
								<div class="col-6 col-12-xsmall">
									<input type="email" name="email" id="email" placeholder="Email" required />
								</div>
								<div class="col-12">
									<textarea name="message" id="message" placeholder="Message" rows="4" required></textarea>
								</div>
								<div class="col-12">
									<input type="checkbox" id="demo-human" name="demo-human" required oninvalid="this.setCustomValidity('Please confirm you are not a robot.')" oninput="this.setCustomValidity('')" />
									<label for="demo-human">👨‍🔬 If I were a robot, I’d be smart enough to hide it better.</label>
								</div>
								<div id="form-message" style="display:none; margin-top: 20px; color: green; font-weight: bold;">
									✅ Thank you! Your message has been sent.
								  </div>
								  
								<div class="col-12">
									<ul class="actions">
									<li><input type="submit" value="Send Message" class="primary" /></li>
									</ul>
								</div>
								</div>
							</form>
							</div>

							<!-- Contact Info -->
							<div class="col-4 col-12-small">
							<ul class="labeled-icons">
								<li>
								<h3 class="icon solid fa-home"><span class="label">Address</span></h3>
								Chemnitz, Germany
								</li>
								<li>
								<h3 class="icon solid fa-mobile-alt"><span class="label">Phone</span></h3>
								(+49) 162-9844945
								</li>
								<li>
								<h3 class="icon solid fa-envelope"><span class="label">Email</span></h3>
								<a href="mailto:talalahmad_20@yahoo.com">talalahmad_20@yahoo.com</a>
								</li>
							</ul>
							</div>
						</div>
						</section>






				<!-- Four -->
				<!--
					<section id="four">
						<h2>Elements</h2>

						<section>
							<h4>Text</h4>
							<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
							This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
							This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
							<hr />
							<header>
								<h4>Heading with a Subtitle</h4>
								<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
							</header>
							<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
							<header>
								<h5>Heading with a Subtitle</h5>
								<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
							</header>
							<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
							<hr />
							<h2>Heading Level 2</h2>
							<h3>Heading Level 3</h3>
							<h4>Heading Level 4</h4>
							<h5>Heading Level 5</h5>
							<h6>Heading Level 6</h6>
							<hr />
							<h5>Blockquote</h5>
							<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
							<h5>Preformatted</h5>
							<pre><code>i = 0;

while (!deck.isInOrder()) {
print 'Iteration ' + i;
deck.shuffle();
i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
						</section>

						<section>
							<h4>Lists</h4>
							<div class="row">
								<div class="col-6 col-12-xsmall">
									<h5>Unordered</h5>
									<ul>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Sagittis adipiscing lorem eleifend.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ul>
									<h5>Alternate</h5>
									<ul class="alt">
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Sagittis adipiscing lorem eleifend.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ul>
								</div>
								<div class="col-6 col-12-xsmall">
									<h5>Ordered</h5>
									<ol>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Etiam vel felis at lorem sed viverra.</li>
										<li>Felis enim feugiat dolore viverra.</li>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Etiam vel felis at lorem sed viverra.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ol>
									<h5>Icons</h5>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
										<li><a href="#" class="icon brands fa-tumblr"><span class="label">Tumblr</span></a></li>
									</ul>
								</div>
							</div>
							<h5>Actions</h5>
							<ul class="actions">
								<li><a href="#" class="button primary">Default</a></li>
								<li><a href="#" class="button">Default</a></li>
							</ul>
							<ul class="actions small">
								<li><a href="#" class="button primary small">Small</a></li>
								<li><a href="#" class="button small">Small</a></li>
							</ul>
							<div class="row">
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary small">Small</a></li>
										<li><a href="#" class="button small">Small</a></li>
									</ul>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary fit">Default</a></li>
										<li><a href="#" class="button fit">Default</a></li>
									</ul>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary small fit">Small</a></li>
										<li><a href="#" class="button small fit">Small</a></li>
									</ul>
								</div>
							</div>
						</section>

						<section>
							<h4>Table</h4>
							<h5>Default</h5>
							<div class="table-wrapper">
								<table>
									<thead>
										<tr>
											<th>Name</th>
											<th>Description</th>
											<th>Price</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td>Item One</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Two</td>
											<td>Vis ac commodo adipiscing arcu aliquet.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Three</td>
											<td> Morbi faucibus arcu accumsan lorem.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Four</td>
											<td>Vitae integer tempus condimentum.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Five</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
									</tbody>
									<tfoot>
										<tr>
											<td colspan="2"></td>
											<td>100.00</td>
										</tr>
									</tfoot>
								</table>
							</div>

							<h5>Alternate</h5>
							<div class="table-wrapper">
								<table class="alt">
									<thead>
										<tr>
											<th>Name</th>
											<th>Description</th>
											<th>Price</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td>Item One</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Two</td>
											<td>Vis ac commodo adipiscing arcu aliquet.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Three</td>
											<td> Morbi faucibus arcu accumsan lorem.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Four</td>
											<td>Vitae integer tempus condimentum.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Five</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
									</tbody>
									<tfoot>
										<tr>
											<td colspan="2"></td>
											<td>100.00</td>
										</tr>
									</tfoot>
								</table>
							</div>
						</section>

						<section>
							<h4>Buttons</h4>
							<ul class="actions">
								<li><a href="#" class="button primary">Primary</a></li>
								<li><a href="#" class="button">Default</a></li>
							</ul>
							<ul class="actions">
								<li><a href="#" class="button large">Large</a></li>
								<li><a href="#" class="button">Default</a></li>
								<li><a href="#" class="button small">Small</a></li>
							</ul>
							<ul class="actions fit">
								<li><a href="#" class="button primary fit">Fit</a></li>
								<li><a href="#" class="button fit">Fit</a></li>
							</ul>
							<ul class="actions fit small">
								<li><a href="#" class="button primary fit small">Fit + Small</a></li>
								<li><a href="#" class="button fit small">Fit + Small</a></li>
							</ul>
							<ul class="actions">
								<li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
								<li><a href="#" class="button icon solid fa-download">Icon</a></li>
							</ul>
							<ul class="actions">
								<li><span class="button primary disabled">Primary</span></li>
								<li><span class="button disabled">Default</span></li>
							</ul>
						</section>

						<section>
							<h4>Form</h4>
							<form method="post" action="#">
								<div class="row gtr-uniform gtr-50">
									<div class="col-6 col-12-xsmall">
										<input type="text" name="demo-name" id="demo-name" value="" placeholder="Name" />
									</div>
									<div class="col-6 col-12-xsmall">
										<input type="email" name="demo-email" id="demo-email" value="" placeholder="Email" />
									</div>
									<div class="col-12">
										<select name="demo-category" id="demo-category">
											<option value="">- Category -</option>
											<option value="1">Manufacturing</option>
											<option value="1">Shipping</option>
											<option value="1">Administration</option>
											<option value="1">Human Resources</option>
										</select>
									</div>
									<div class="col-4 col-12-small">
										<input type="radio" id="demo-priority-low" name="demo-priority" checked>
										<label for="demo-priority-low">Low Priority</label>
									</div>
									<div class="col-4 col-12-small">
										<input type="radio" id="demo-priority-normal" name="demo-priority">
										<label for="demo-priority-normal">Normal Priority</label>
									</div>
									<div class="col-4 col-12-small">
										<input type="radio" id="demo-priority-high" name="demo-priority">
										<label for="demo-priority-high">High Priority</label>
									</div>
									<div class="col-6 col-12-small">
										<input type="checkbox" id="demo-copy" name="demo-copy">
										<label for="demo-copy">Email me a copy of this message</label>
									</div>
									<div class="col-6 col-12-small">
										<input type="checkbox" id="demo-human" name="demo-human" checked>
										<label for="demo-human">I am a human and not a robot</label>
									</div>
									<div class="col-12">
										<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
									</div>
									<div class="col-12">
										<ul class="actions">
											<li><input type="submit" value="Send Message" class="primary" /></li>
											<li><input type="reset" value="Reset" /></li>
										</ul>
									</div>
								</div>
							</form>
						</section>

						<section>
							<h4>Image</h4>
							<h5>Fit</h5>
							<div class="box alt">
								<div class="row gtr-50 gtr-uniform">
									<div class="col-12"><span class="image fit"><img src="images/fulls/05.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/04.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/05.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/06.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
								</div>
							</div>
							<h5>Left &amp; Right</h5>
							<p><span class="image left"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
							<p><span class="image right"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
						</section>

					</section>
				 -->

			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="mailto:talalahmad_20@yahoo.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
						<li><a href="https://www.linkedin.com/in/talalahmad99/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
						<li><a href="https://github.com/Azad99" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="https://medium.com/@talalahmad_20" class="icon brands fa-medium"><span class="label">Medium</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Talal Ahmad</li><li>2025</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script>
			function openModal(id) {
				document.getElementById(id).style.display = "block";
			}
			function closeModal(id) {
				document.getElementById(id).style.display = "none";
			}

			// Optional: Close modal on outside click
			window.onclick = function (event) {
				const modals = document.getElementsByClassName("custom-modal");
				Array.from(modals).forEach((modal) => {
				if (event.target === modal) {
					modal.style.display = "none";
				}
				});
			};
			</script>
			<script>
				document.getElementById("contact-form").addEventListener("submit", async function(e) {
				  e.preventDefault(); // Prevent normal form submit
				
				  const form = e.target;
				  const data = new FormData(form);
				
				  try {
					const response = await fetch(form.action, {
					  method: "POST",
					  body: data,
					  headers: {
						'Accept': 'application/json'
					  }
					});
				
					if (response.ok) {
					  document.getElementById("form-message").style.display = "block";
					  form.reset(); // Clear the form
					} else {
					  alert("Oops! There was a problem submitting your form.");
					}
				  } catch (error) {
					alert("Oops! Something went wrong.");
				  }
				});
				</script>
				


	</body>
</html>